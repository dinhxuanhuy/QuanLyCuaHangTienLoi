using Microsoft.SemanticKernel;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;
using System.Text;

Console.OutputEncoding = Encoding.UTF8;
Console.InputEncoding = Encoding.UTF8;
    
string apiKey = "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";
string modelId = "gpt-4o-mini";
string connectionString = "Data Source=HUY-G14;Initial Catalog=QuanLyCuaHangTienLoi;Integrated Security=True;Encrypt=True;TrustServerCertificate=True";

var kernel = Kernel.CreateBuilder().AddOpenAIChatCompletion(modelId, apiKey).Build();

kernel.Plugins.AddFromObject(new SQLAgentConsole.Plugin(connectionString));
var chatService = kernel.GetRequiredService<IChatCompletionService>();
//make a welcome message
Console.WriteLine("welcome to my chatbot SQL agent");
Console.WriteLine("Type exit to quit");
while (true)
{
    Console.Write("You:");
    var question = Console.ReadLine();
    if (String.IsNullOrEmpty(question) || question.ToLower() == "exit")
    {
        break;
    }
    try
    {
        var answer = await GetAnswer(chatService, kernel, question);
        Console.WriteLine($"AI: {answer}");


    }
    catch (Exception ex)
    {
        Console.WriteLine($"Error: {ex.Message}");

    }
}
static async Task<String> GetAnswer(IChatCompletionService chatservice , Kernel kernel , String question)
{
    var chat = new ChatHistory();
    chat.AddSystemMessage(@"You are a helpful AI assistant for a store management application.
When user ask questions , generate appropriate SQL queries to retrieve the necessary data.
Always be friendly and explain your clearly.");
    chat.AddUserMessage(question);
    var settings = new OpenAIPromptExecutionSettings()
    {
        ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions,
        Temperature = 0.1,
    };
    var response = await chatservice.GetChatMessageContentAsync(chat, settings, kernel);
    return response.Content ?? "I'm sorry, I don't have an answer for that.";
}
 


/*
var endpoint = new Uri("http://localhost:11434");
var modelId = "phi3:3.8b";

var kernelBuilder = Kernel.CreateBuilder();

kernelBuilder.Services.AddHttpClient();

kernelBuilder.AddOllamaChatCompletion(
    modelId: modelId,
    endpoint: endpoint
);

const string promptTemplate = @"
You are a helpful AI assistant.
Conversation so far , maybe the history can blank , just greet them and answer based on their question:
{history}

User: {userInput}
Assistant:
";

var kernel = kernelBuilder.Build();

var history = "";
var arguments = new KernelArguments
{
    ["history"] = history
};

var chatFunction = kernel.CreateFunctionFromPrompt(promptTemplate);

while (true)
{
    Console.Write("User: ");
    var userInput = Console.ReadLine();

    if (string.IsNullOrWhiteSpace(userInput))
        continue;

    if (userInput.Equals("exit", StringComparison.OrdinalIgnoreCase))
        break;

    arguments["userInput"] = userInput;

    var answer = await chatFunction.InvokeAsync(kernel, arguments);

    history += $"\nUser: {userInput}\nAssistant: {answer}\n";
    arguments["history"] = history;

    Console.WriteLine($"Assistant: {answer}");
}
*/
